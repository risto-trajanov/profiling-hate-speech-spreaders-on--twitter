{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preparation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "green-chess"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOcRLcsiYyRi",
        "outputId": "7aeed8d9-5e2f-4a60-f762-3dd8c2815d0a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g573ru6TZUh7",
        "outputId": "674644c5-3f97-406e-ad1d-da0322408a3c"
      },
      "source": [
        "%cd drive/MyDrive/Fax/FINKI/Semestar-7/NLP/Project/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fax/FINKI/Semestar-7/NLP/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmPzZA5HZsIK",
        "outputId": "4083d1b7-415d-4ac6-a7a8-47c51385e89f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "divided-kenya"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "import re\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import xml.etree.ElementTree as ET\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english')) \n",
        "lemmatizer = nltk.WordNetLemmatizer()\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *"
      ],
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d63AwN1ssDLb"
      },
      "source": [
        "results_folder = f'./Results/'"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y0kldfnsL1H"
      },
      "source": [
        "os.makedirs(results_folder, exist_ok=True)"
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adverse-childhood"
      },
      "source": [
        "pwd = '/content/drive/MyDrive/Fax/FINKI/Semestar-7/NLP/Project'\n",
        "data_folder = f'{pwd}/data/'\n",
        "truth_file = f'{pwd}/data/truth.txt'"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "academic-attempt"
      },
      "source": [
        "# Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5_EYVqBjq4H"
      },
      "source": [
        "stemmer = SnowballStemmer(language='english')\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSEpxoqPornM"
      },
      "source": [
        "def flat_list(var):\n",
        "    flat = [item for sublist in var for item in sublist]\n",
        "    return flat"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "answering-pledge",
        "outputId": "df810f2e-f719-4711-a95a-c74c6d347c2a"
      },
      "source": [
        "truth_df = pd.read_csv(truth_file, delimiter=\":::\", header=None)\n",
        "truth_df.columns = ['id', 'class']"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incomplete-paper"
      },
      "source": [
        "data_files = os.listdir(data_folder)"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "robust-sunset"
      },
      "source": [
        "tweets = []\n",
        "class_list = []\n",
        "for file in data_files:\n",
        "    if file.endswith('.xml'):\n",
        "        root = ET.parse(data_folder + file).getroot()\n",
        "        for node in root.iter('documents'):\n",
        "            for elem in node.iter():\n",
        "                if not elem.tag==node.tag:\n",
        "                    class_item = truth_df[truth_df['id'] == file[:-4]]['class'].item()\n",
        "                    class_list.append(class_item)\n",
        "                    tweets.append(elem.text)"
      ],
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stuffed-adapter"
      },
      "source": [
        "df = pd.DataFrame({'tweet': tweets, 'class': class_list})"
      ],
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgRukePgxYee"
      },
      "source": [
        "df['tweet_low'] = df['tweet'].apply(lambda x: x if type(x)!=str else x.lower())"
      ],
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuN3oaL_xYet"
      },
      "source": [
        "df['no_url'] = [tweet.replace('#url#', '') for tweet  in df['tweet_low']]"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSSab7e2xYet"
      },
      "source": [
        "df['no_user'] = [tweet.replace('#user#', '') for tweet  in df['no_url']]"
      ],
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXxxMCC1yf2i"
      },
      "source": [
        "df['no_hashtag'] = [tweet.replace('#hashtag#', '') for tweet  in df['no_user']]"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-dTp8gxxYeu"
      },
      "source": [
        "df['no_user_no_special'] = df['no_hashtag'].str.replace(\"[^a-zA-Z#']\", \" \")"
      ],
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "individual-magic"
      },
      "source": [
        "tweets = df['no_user_no_special']\n",
        "tweets_clean = []\n",
        "for tweet in tweets:\n",
        "    tweet = nltk.word_tokenize(tweet)\n",
        "    tweet = [word for word in tweet if not word in stop_words]\n",
        "    tweet = [re.sub(r'[^\\w\\s]','',word) for word in tweet]\n",
        "    tweet = [lemmatizer.lemmatize(each_word, pos='v') for each_word in tweet]\n",
        "    tweet = [word for word in tweet if len(word)>2]\n",
        "    tweets_clean.append(' '.join(tweet))"
      ],
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acting-going"
      },
      "source": [
        "df['removed_stop_and_lem'] = tweets_clean"
      ],
      "execution_count": 407,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_tadbrt0U0i"
      },
      "source": [
        "tweets = df['no_user_no_special']\n",
        "tweets_clean = []\n",
        "for tweet in tweets:\n",
        "    tweet = nltk.word_tokenize(tweet)\n",
        "    tweet = [word for word in tweet if not word in stop_words]\n",
        "    tweet = [re.sub(r'[^\\w\\s]','',word) for word in tweet]\n",
        "    tweet = [word for word in tweet if len(word)>2]\n",
        "    tweets_clean.append(' '.join(tweet))"
      ],
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67XKSeYp0XcE"
      },
      "source": [
        "df['removed_stop'] = tweets_clean"
      ],
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS6HDqYEyAdy"
      },
      "source": [
        "df_renamed = df.rename(columns={'tweet': 'raw_tweet', 'class':'class', 'removed_stop':'tweet'})"
      ],
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aggressive-feedback"
      },
      "source": [
        "df_renamed = df_renamed[['tweet', 'class']]\n",
        "df_renamed.to_csv(\"./raw_data.csv\")"
      ],
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grave-tower"
      },
      "source": [
        "df['tweet_length'] = df['removed_stop_and_lem'].apply(lambda x: len(x.split()))"
      ],
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdzs_8eRlVnN",
        "outputId": "71389751-cfe3-4615-91b9-010784ac610b"
      },
      "source": [
        "print(df['removed_stop_and_lem'][0])\n",
        "print(df['tweet'][0])"
      ],
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mississippi governor ban transgenders participate female sport\n",
            "Mississippi Governor Bans Transgenders From Participating In Female Sports #URL#\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "political-input"
      },
      "source": [
        "df = df[df['tweet_length'] > 2]"
      ],
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "passing-building",
        "outputId": "bbcfa6e2-f359-44be-9a18-da3c70eed529"
      },
      "source": [
        "df"
      ],
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet_low</th>\n",
              "      <th>no_url</th>\n",
              "      <th>no_user</th>\n",
              "      <th>no_hashtag</th>\n",
              "      <th>no_user_no_special</th>\n",
              "      <th>removed_stop_and_lem</th>\n",
              "      <th>removed_stop</th>\n",
              "      <th>tweet_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mississippi Governor Bans Transgenders From Pa...</td>\n",
              "      <td>0</td>\n",
              "      <td>mississippi governor bans transgenders from pa...</td>\n",
              "      <td>mississippi governor bans transgenders from pa...</td>\n",
              "      <td>mississippi governor bans transgenders from pa...</td>\n",
              "      <td>mississippi governor bans transgenders from pa...</td>\n",
              "      <td>mississippi governor bans transgenders from pa...</td>\n",
              "      <td>mississippi governor ban transgenders particip...</td>\n",
              "      <td>mississippi governor bans transgenders partici...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LIBERAL LUNACY: Ice Cream Flavor Name Changed ...</td>\n",
              "      <td>0</td>\n",
              "      <td>liberal lunacy: ice cream flavor name changed ...</td>\n",
              "      <td>liberal lunacy: ice cream flavor name changed ...</td>\n",
              "      <td>liberal lunacy: ice cream flavor name changed ...</td>\n",
              "      <td>liberal lunacy: ice cream flavor name changed ...</td>\n",
              "      <td>liberal lunacy  ice cream flavor name changed ...</td>\n",
              "      <td>liberal lunacy ice cream flavor name change du...</td>\n",
              "      <td>liberal lunacy ice cream flavor name changed d...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AOC, Nadler Call on N.Y. Gov. Andrew Cuomo to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>aoc, nadler call on n.y. gov. andrew cuomo to ...</td>\n",
              "      <td>aoc, nadler call on n.y. gov. andrew cuomo to ...</td>\n",
              "      <td>aoc, nadler call on n.y. gov. andrew cuomo to ...</td>\n",
              "      <td>aoc, nadler call on n.y. gov. andrew cuomo to ...</td>\n",
              "      <td>aoc  nadler call on n y  gov  andrew cuomo to ...</td>\n",
              "      <td>aoc nadler call gov andrew cuomo resign via</td>\n",
              "      <td>aoc nadler call gov andrew cuomo resign via</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WATCH: Mark Levin goes NUCLEAR on Joe Biden fo...</td>\n",
              "      <td>0</td>\n",
              "      <td>watch: mark levin goes nuclear on joe biden fo...</td>\n",
              "      <td>watch: mark levin goes nuclear on joe biden fo...</td>\n",
              "      <td>watch: mark levin goes nuclear on joe biden fo...</td>\n",
              "      <td>watch: mark levin goes nuclear on joe biden fo...</td>\n",
              "      <td>watch  mark levin goes nuclear on joe biden fo...</td>\n",
              "      <td>watch mark levin nuclear joe biden try take cr...</td>\n",
              "      <td>watch mark levin goes nuclear joe biden trying...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>New York Legislature Just Took 'First Step' To...</td>\n",
              "      <td>0</td>\n",
              "      <td>new york legislature just took 'first step' to...</td>\n",
              "      <td>new york legislature just took 'first step' to...</td>\n",
              "      <td>new york legislature just took 'first step' to...</td>\n",
              "      <td>new york legislature just took 'first step' to...</td>\n",
              "      <td>new york legislature just took 'first step' to...</td>\n",
              "      <td>new york legislature take first step toward im...</td>\n",
              "      <td>new york legislature took first step toward im...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39995</th>\n",
              "      <td>😂😂😂periodt i had to put my name in all CAPS #URL#</td>\n",
              "      <td>1</td>\n",
              "      <td>😂😂😂periodt i had to put my name in all caps #url#</td>\n",
              "      <td>😂😂😂periodt i had to put my name in all caps</td>\n",
              "      <td>😂😂😂periodt i had to put my name in all caps</td>\n",
              "      <td>😂😂😂periodt i had to put my name in all caps</td>\n",
              "      <td>periodt i had to put my name in all caps</td>\n",
              "      <td>periodt put name cap</td>\n",
              "      <td>periodt put name caps</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>RT #USER#: sorry if im becoming distant, im tr...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt #user#: sorry if im becoming distant, im tr...</td>\n",
              "      <td>rt #user#: sorry if im becoming distant, im tr...</td>\n",
              "      <td>rt : sorry if im becoming distant, im trying t...</td>\n",
              "      <td>rt : sorry if im becoming distant, im trying t...</td>\n",
              "      <td>rt   sorry if im becoming distant  im trying t...</td>\n",
              "      <td>sorry become distant try</td>\n",
              "      <td>sorry becoming distant trying</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>RT #USER#: My next hair appointment the only t...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt #user#: my next hair appointment the only t...</td>\n",
              "      <td>rt #user#: my next hair appointment the only t...</td>\n",
              "      <td>rt : my next hair appointment the only thing i...</td>\n",
              "      <td>rt : my next hair appointment the only thing i...</td>\n",
              "      <td>rt   my next hair appointment the only thing i...</td>\n",
              "      <td>next hair appointment thing worry</td>\n",
              "      <td>next hair appointment thing worried</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>RT #USER#: One thing about me ima go to sleep. 😂</td>\n",
              "      <td>1</td>\n",
              "      <td>rt #user#: one thing about me ima go to sleep. 😂</td>\n",
              "      <td>rt #user#: one thing about me ima go to sleep. 😂</td>\n",
              "      <td>rt : one thing about me ima go to sleep. 😂</td>\n",
              "      <td>rt : one thing about me ima go to sleep. 😂</td>\n",
              "      <td>rt   one thing about me ima go to sleep</td>\n",
              "      <td>one thing ima sleep</td>\n",
              "      <td>one thing ima sleep</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39999</th>\n",
              "      <td>RT #USER#: 1 thing bout me I don’t be giving a...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt #user#: 1 thing bout me i don’t be giving a...</td>\n",
              "      <td>rt #user#: 1 thing bout me i don’t be giving a...</td>\n",
              "      <td>rt : 1 thing bout me i don’t be giving a damn ...</td>\n",
              "      <td>rt : 1 thing bout me i don’t be giving a damn ...</td>\n",
              "      <td>rt     thing bout me i don t be giving a damn ...</td>\n",
              "      <td>thing bout give damn fuck</td>\n",
              "      <td>thing bout giving damn fuck</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33217 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet  ...  tweet_length\n",
              "0      Mississippi Governor Bans Transgenders From Pa...  ...             7\n",
              "1      LIBERAL LUNACY: Ice Cream Flavor Name Changed ...  ...            10\n",
              "2      AOC, Nadler Call on N.Y. Gov. Andrew Cuomo to ...  ...             8\n",
              "3      WATCH: Mark Levin goes NUCLEAR on Joe Biden fo...  ...            11\n",
              "4      New York Legislature Just Took 'First Step' To...  ...            10\n",
              "...                                                  ...  ...           ...\n",
              "39995  😂😂😂periodt i had to put my name in all CAPS #URL#  ...             4\n",
              "39996  RT #USER#: sorry if im becoming distant, im tr...  ...             4\n",
              "39997  RT #USER#: My next hair appointment the only t...  ...             5\n",
              "39998   RT #USER#: One thing about me ima go to sleep. 😂  ...             4\n",
              "39999  RT #USER#: 1 thing bout me I don’t be giving a...  ...             5\n",
              "\n",
              "[33217 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 415
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zq8rApcmNtc"
      },
      "source": [
        "df = df.rename(columns={'tweet': 'raw_tweet', 'class':'class', 'removed_stop_and_lem':'tweet'})"
      ],
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu4PawD286N1"
      },
      "source": [
        "df[['tweet', 'class']].to_csv('./dataset.csv')"
      ],
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEkw11HWmbff"
      },
      "source": [
        "df_final = df[['tweet', 'class']]"
      ],
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-E1gk4zvOH4"
      },
      "source": [
        "# Cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HplI9zVYvbro"
      },
      "source": [
        "df = pd.read_csv('./dataset.csv')"
      ],
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX7gnsaUm962"
      },
      "source": [
        "df_hate = df[df['class'] == 1]\n",
        "df_no_hate = df[df['class'] == 0]"
      ],
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbMO8IoboFbR"
      },
      "source": [
        "tweets_hate = df_hate['tweet']\n",
        "tweets_hate = (list(tweets_hate))\n",
        "tweets_hate = [x for x in tweets_hate if str(x) != 'nan']\n",
        "tweets_no_hate = df_no_hate['tweet']\n",
        "tweets_no_hate = (list(tweets_no_hate))\n",
        "tweets_no_hate = [x for x in tweets_no_hate if str(x) != 'nan']"
      ],
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvNrMc84s1jg"
      },
      "source": [
        "## Average words in tweets after cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPUU522knDh2",
        "outputId": "828d6f3d-6910-4f51-dca7-986aa9650cc5"
      },
      "source": [
        "number_of_words = 0\n",
        "tweet_len = []\n",
        "for tweet in tweets_hate:\n",
        "    number_of_words += len(tweet)\n",
        "    tweet_len.append(len(tweet))\n",
        "avg_words_in_tweet = round(number_of_words/len(df_hate))\n",
        "print((number_of_words/len(df_hate)))"
      ],
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38.48608355876165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VmQdI5FoBR8",
        "outputId": "3b58f12a-29bc-4cd6-a174-e5eeeae1c07f"
      },
      "source": [
        "number_of_words = 0\n",
        "tweet_len = []\n",
        "for tweet in tweets_no_hate:\n",
        "    number_of_words += len(tweet)\n",
        "    tweet_len.append(len(tweet))\n",
        "avg_words_in_tweet = round(number_of_words/len(df_hate))\n",
        "print((number_of_words/len(df_hate)))"
      ],
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38.18755635707845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrHRt-cqs55Q"
      },
      "source": [
        "## Word counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewct2dmGoNuE"
      },
      "source": [
        "tweets_hate_flat = [' '.join(tweets_hate[:])]"
      ],
      "execution_count": 424,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kxGv9Bircot"
      },
      "source": [
        "tweets_hate_flat = tweets_hate_flat[0].split()"
      ],
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR-yBF_gosnb"
      },
      "source": [
        "tweets_hate_count = Counter(tweets_hate_flat)"
      ],
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFqB9bWFoxET"
      },
      "source": [
        "tweets_hate_count_df = pd.DataFrame(tweets_hate_count.most_common())\n",
        "tweets_hate_count_df.columns = ['words', 'count']"
      ],
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttl8oXCao71r"
      },
      "source": [
        "tweets_hate_count_df_10 = tweets_hate_count_df[tweets_hate_count_df['count'] > 10]\n",
        "tweets_hate_count_df_10.to_csv('./Results/tweets_hate_count_df_10.csv')"
      ],
      "execution_count": 428,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR9kaRJ9shPG"
      },
      "source": [
        "tweets_no_hate_flat = [' '.join(tweets_no_hate[:])]"
      ],
      "execution_count": 429,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBcmmb0qshPG"
      },
      "source": [
        "tweets_no_hate_flat = tweets_no_hate_flat[0].split()"
      ],
      "execution_count": 430,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7QkUmm6shPH"
      },
      "source": [
        "tweets_no_hate_count = Counter(tweets_no_hate_flat)"
      ],
      "execution_count": 431,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cws4CI4ZshPH"
      },
      "source": [
        "tweets_no_hate_count_df = pd.DataFrame(tweets_no_hate_count.most_common())\n",
        "tweets_no_hate_count_df.columns = ['words', 'count']"
      ],
      "execution_count": 432,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8WbaF6bshPI"
      },
      "source": [
        "tweets_no_hate_count_df_10 = tweets_no_hate_count_df[tweets_no_hate_count_df['count'] > 10]\n",
        "tweets_no_hate_count_df_10.to_csv('./Results/tweets_no_hate_count_df_10.csv')"
      ],
      "execution_count": 433,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "icgVHfCdy_Tw",
        "outputId": "999d3ab6-2bc7-4cc5-b620-36485bcc3f2d"
      },
      "source": [
        "tweets_no_hate_count_df_10"
      ],
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>get</td>\n",
              "      <td>1337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>like</td>\n",
              "      <td>944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>one</td>\n",
              "      <td>739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>people</td>\n",
              "      <td>666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>say</td>\n",
              "      <td>610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1653</th>\n",
              "      <td>tuesday</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1654</th>\n",
              "      <td>title</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1655</th>\n",
              "      <td>guest</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1656</th>\n",
              "      <td>fkn</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1657</th>\n",
              "      <td>mobile</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1658 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        words  count\n",
              "0         get   1337\n",
              "1        like    944\n",
              "2         one    739\n",
              "3      people    666\n",
              "4         say    610\n",
              "...       ...    ...\n",
              "1653  tuesday     11\n",
              "1654    title     11\n",
              "1655    guest     11\n",
              "1656      fkn     11\n",
              "1657   mobile     11\n",
              "\n",
              "[1658 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Gg8dO5vJf7"
      },
      "source": [
        "# Raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZdV3YkzsdTk"
      },
      "source": [
        "df = pd.read_csv('./raw_data.csv')"
      ],
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHoIjQaPvH_M"
      },
      "source": [
        "df_hate = df[df['class'] == 1]\n",
        "df_no_hate = df[df['class'] == 0]"
      ],
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7yAWlfZvH_M"
      },
      "source": [
        "tweets_hate = df_hate['tweet']\n",
        "tweets_hate = (list(tweets_hate))\n",
        "tweets_hate = [x for x in tweets_hate if str(x) != 'nan']\n",
        "tweets_no_hate = df_no_hate['tweet']\n",
        "tweets_no_hate = (list(tweets_no_hate))\n",
        "tweets_no_hate = [x for x in tweets_no_hate if str(x) != 'nan']"
      ],
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmeALp0ovH_N"
      },
      "source": [
        "## Average words in tweets after cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_ZpxPXWvH_N",
        "outputId": "b42bc921-f4eb-4722-b8fb-e257a5500bec"
      },
      "source": [
        "number_of_words = 0\n",
        "tweet_len = []\n",
        "for tweet in tweets_hate:\n",
        "    number_of_words += len(tweet)\n",
        "    tweet_len.append(len(tweet))\n",
        "avg_words_in_tweet = round(number_of_words/len(df_hate))\n",
        "print((number_of_words/len(df_hate)))"
      ],
      "execution_count": 438,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35.1442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGDq3EoCvH_O",
        "outputId": "0a18e970-fc55-4a23-e19d-b44f56684003"
      },
      "source": [
        "number_of_words = 0\n",
        "tweet_len = []\n",
        "for tweet in tweets_no_hate:\n",
        "    number_of_words += len(tweet)\n",
        "    tweet_len.append(len(tweet))\n",
        "avg_words_in_tweet = round(number_of_words/len(df_hate))\n",
        "print((number_of_words/len(df_hate)))"
      ],
      "execution_count": 439,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34.97385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BT4qVCZvH_O"
      },
      "source": [
        "## Word counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVt-C8jtvH_O"
      },
      "source": [
        "tweets_hate_flat = [' '.join(tweets_hate[:])]"
      ],
      "execution_count": 440,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk4wYod3vH_P"
      },
      "source": [
        "tweets_hate_flat = tweets_hate_flat[0].split()"
      ],
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee7qNrSqvH_P"
      },
      "source": [
        "tweets_hate_count = Counter(tweets_hate_flat)"
      ],
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKHuPxTRvH_P"
      },
      "source": [
        "tweets_hate_count_df = pd.DataFrame(tweets_hate_count.most_common())\n",
        "tweets_hate_count_df.columns = ['words', 'count']"
      ],
      "execution_count": 443,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su2jQj0FvH_P"
      },
      "source": [
        "tweets_hate_count_df_10 = tweets_hate_count_df[tweets_hate_count_df['count'] > 10]\n",
        "tweets_hate_count_df_10.to_csv('./Results/raw_tweets_hate_count_df_10.csv')"
      ],
      "execution_count": 444,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxTKDq2cvH_R"
      },
      "source": [
        "tweets_no_hate_flat = [' '.join(tweets_no_hate[:])]"
      ],
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C95YOPdvvH_R"
      },
      "source": [
        "tweets_no_hate_flat = tweets_no_hate_flat[0].split()"
      ],
      "execution_count": 446,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFU8UN8bvH_R"
      },
      "source": [
        "tweets_no_hate_count = Counter(tweets_no_hate_flat)"
      ],
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNpFUv_xvH_R"
      },
      "source": [
        "tweets_no_hate_count_df = pd.DataFrame(tweets_no_hate_count.most_common())\n",
        "tweets_no_hate_count_df.columns = ['words', 'count']"
      ],
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGEkay3YvH_S"
      },
      "source": [
        "tweets_no_hate_count_df_10 = tweets_no_hate_count_df[tweets_no_hate_count_df['count'] > 10]\n",
        "tweets_no_hate_count_df_10.to_csv('./Results/raw_tweets_no_hate_count_df_10.csv')"
      ],
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV7t1lvgvTmd"
      },
      "source": [
        ""
      ],
      "execution_count": 449,
      "outputs": []
    }
  ]
}